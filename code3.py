def plots(imgs, titles):
    imgs= np.array(imgs).astype (np. uint8)
    # if type(ims[0]) is np.ndarray: 
    #   ims np.array(ims).astype (np. uint8)
    #   if (ims.shape[-1] != 3):
    #       ims ims.transpose((0,2,3,1))
    f = plt.figure(figsize=(20, 20))
    rows=10
    cols=10 # len(ims)//rows if len(ims) % 2e else len(ims)//rows + 1
    for i in range(0,50):
        sp=f.add_subplot(rows, cols, i+1)
        sp.axis('off')
        if titles is not None:
            sp.set_title(list(batches.class_indices.keys())[np.argmax(titles[i])])
        plt.imshow(imgs[i])
        



def malware_cnn_model():

    Malware_model = Sequential () 
    Malware_model.add(Conv2D(30, kernel_size=(3, 3),
            activation= 'relu',
            input_shape=(64,64,3)))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
    Malware_model.add(Conv2D(15, (3, 3), activation='relu'))
    Malware_model.add(MaxPooling2D(pool_size=(2, 2)))
    Malware_model.add(Dropout(0.25))
    Malware_model.add(Flatten()) 
    Malware_model.add(Dense(128, activation='relu'))
    Malware_model.add (Dropout (0.5))
    Malware_model.add(Dense (50, activation='relu'))
    Malware_model.add(Dense (25, activation='softmax')) 
    Malware_model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
    return Malware_model




def malware_model():
    img_size =64
    left_inputs = Input(shape=(img_size, img_size, 3))
    filters=32
    x = left_inputs
    for i in range(3):
        x = Conv2D(filters,3,activation='relu', padding='same')(x)
        x = Dropout(0.3)(x)
        x= MaxPooling2D()(x) 
        filters*=2
        right_inputs=Input(shape=(img_size, img_size, 3)) 
        y=right_inputs
        filters=32
    for i in range(3):
        y = Conv2D(filters, 3, activation='relu',padding='same', dilation_rate=2)
        y = Dropout(0.3)(y)
        y = MaxPooling2D()(y)
        filters*=2
    y=concatenate([x,y])
    y = Flatten()(y)
    y=Dropout(0.3)(y)
    op = Dense (25, activation='softmax')(y)
    model = Model (inputs=[left_inputs, right_inputs], outputs=op) 
    model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])
    return model





import seaborn as sns
def confusion_matrix(confusion matrix, class_names, figsize = (10,7), fontsize=14):
    df_cm = pd.DataFrame(
        confusion_matrix, index=class_names, columns=class_names,
    )
    fig = plt.figure(figsize=figsize)
    try:
        heatmap = sns.heatmap(df_cm, annot=True, fmt="d") 
    except ValueError:
        raise ValueError("Confusion matrix values must be integers.")
    heatmap.yaxis.set_ticklabels (heatmap.yaxis.get_ticklabels (), rotation=0, ha='right', fontsize=fontsize) 
    heatmap.xaxis.set_ticklabels (heatmap.xaxis.get_ticklabels (), rotation=45, ha='right', fontsize=fontsize)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    
    
 


def add_gaussian_noise (X_imgs): 
    gaussian noise_imgs = [] 
    row, col,_= X_imgs[0].shape
    # Gaussian distribution parameters
    mean =0
    var=0.1
    sigma =var ** 0.5
    for X_img in X_imgs:
        gaussian = np.random.random((row, col, 1)).astype (np.float32) 
        gaussian =np.concatenate ((gaussian, gaussian, gaussian), axis=2) 
        gaussian_img= cv2.addWeighted (X_img, 0.75, 0.25*gaussian, 0.25, 0) 
        gaussian noise_imgs.append(gaussian_img)
    gaussian_noise_imgs= np.array(gaussian_noise_imgs, dtype np.float32) 
    return gaussian_noise_imgs
x_train_noisy= add_gaussian_noise(X_train)





def make generator_model():
    model=tf.keras.Sequential()
    model.add(layers.Dense (8*8*512, use_bias=False, input_shape=(64*64*3,))) 
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((8, 8, 512)))
    assert model.output_shape == (None, 8, 8, 512) #Note: None is the batch size
    model.add(layers. Conv2DTranspose (256, (5, 5), strides (1, 1), padding='same', use_bias=False)) 
    assert model.output_shape== (None, 8, 8, 256)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(128, (5, 5), strides =(2, 2), padding='same', use_bias=False)) 
    assert model.output_shape== (None, 16, 16, 128) 
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides= (2, 2), padding='same', use_bias=False))
    assert model.output_shape== (None, 32, 32, 64) 
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    
    model.add(layers.Conv2DTranspose(3, (5, 5), strides =(2, 2), padding='same', use_bias=False, activation='tanh'))
    assert model.output shape == (None, 64, 64, 3)
    return model
